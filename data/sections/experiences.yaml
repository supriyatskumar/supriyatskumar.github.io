# section information
section:
  name: Experiences
  id: experiences
  enable: true
  weight: 3
  showOnNavbar: true
  # Can optionally hide the title in sections
  # hideTitle: true

# Your experiences
experiences:
- company:
    name: PHOENIX program, Wayne State University
    url: "https://phoenix.wayne.edu/about"
    location: Detroit MI
    # company overview
    overview: The Population Health Outcomes and Information Exchange (PHOENIX) Program
  positions:
  - designation: Data Scientist
    start: June 2020
    end: March 2021
    # don't provide end date if you are currently working there. It will be replaced by "Present"
    # end: Dec 2020
    # give some points about what was your responsibilities at the company.
    responsibilities:
    - "Deployed a text similarity Natural Language Processing (NLP) technique on GCP to create a unified covid-19 survey dataset by
    combining 20 disparate surveys, reducing 15 hours of manual work per week."
    - "Built web scraper to automate weekly and monthly data ingestion using BeautifulSoup, Selenium, Google Cloud Functions and Scheduler,
    saving external vendor costs of $30k annually."
    - "Utilized Google Compute Engine to schedule python scripts for cleaning and pre-processing large datasets,
    resulting in improved data pre-processing speed by 80%."

- company:
    name: Trustworthy AI Lab, Wayne State University,  -
    url: "https://sites.google.com/view/mlpa/mainpage"
    location: Detroit MI
    overview: Mentor [Dr. Dongxiao Zhu](https://dongxiaozhu.github.io/)
  positions:
  - designation: Machine Learning Research Assistant
    start: September 2019
    end: March 2021
    responsibilities:
    - "Collaborated to design new training scheme for model compression ensuring adversarial robustness, explainability and
    personalization for NLP applications. preprint arXiv:2101.05624."
    - "Implemented On-Device model personalization-trained global model on a sentiment dataset collected from 5000 users and
    then fine-tuned it on each user’s private training data."
    - "Extracted static geospatial features from 20,000 geocoded POIs in Detroit using PCA and clustering and explained it in
    terms of POI types to learn semantic similarities between regions for efficient public health surveillance.
    (Clients- School of Medicine Wayne State University & Detroit Department of Health)"
    - "Curated Yelp review dataset of 50k restaurant reviews and ratings using Python and Beautiful Soup for sentiment classification."

- company:
    name: Neo Prism Solutions LLC
    url: "https://neoprisminc.com/"
    location: Schaumburg, IL
    #overview: Intern counting Company (ICC) is responsible for counting worldwide intern Engineers.
  positions:
  - designation: Data Analyst Consultant
    start: June 2015
    end: June 2018
    responsibilities:
    - <mark>Client- Sally Beauty Holdings</mark>
    - "Built an end-to-end analytics pipeline for data extraction, processing and reporting of payroll and census data using SQL and Alteryx,
    saving the company $500k annually in reduced overtime cost."
    - "Developed an interactive dashboard to report transactions and sales of ~3000 stores in real time and
    communicated the key findings to the leadership."
    - <mark>Client- Adams Street Partners</mark>
    - "Trained 20 executives to build ad-hoc Tableau reports reducing 10 hours per week of manual work to generate single use reports."
    - "Developed a client interactions dashboard with details of 30 days prior and subsequent interactions, resulting in 10% increase in deal completion."
    - <mark>Client- Blue Cross Blue Shield of Illinois</mark>
    - "Created tableau custom geo code map based on three-digit US Zip codes for tracking plan providers’ participation."
    - "Built workflow for design, development and maintenance of ongoing metrics, reports, and dashboards to drive key
    conclusions on each Blue Distinction Specialty Care."
    - <mark>Client- Compassion International</mark>
    - "Developed Tableau dashboard to track high-risk hourly transaction errors logged by Enterprise Service Bus (ESB),
    reducing the error handling time by 60%."
    - "Created reusable SQL queries to port daily ESB audit data into Netezza resulting in improved production database performance by 12%."
    - "Collaborated with marketing team to analyse data using Python and SQL to generate Tableau visualizations for latest sponsorships and campaign;
    led to $50k in new sponsorships."
